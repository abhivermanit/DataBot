Downstream Pipeline :---

We use Apache Oozie to orchestrate our workflows, and this (show image if allowed) is a typical example of our pipeline visualized as a DAG (Directed Acyclic Graph).

The pipeline starts with two initialization steps:
generate-pipeline → patch-secrets-in-pipeline — these typically prepare configurations and secrets for the job.

Then, it kicks off the actual ETL flow with processMaintenanceDelta which is likely responsible for identifying or extracting delta (incremental) data.

Next, processMaintenanceTodoDetailsDump and MaintenanceTablesProcessing_1 are core aggregation or staging steps. They prepare multiple datasets.

Notice that after MaintenanceTablesProcessing_1, the pipeline fans out (parallelism) into multiple tasks:

processMaintenanceTicketEventsTables

processMaintenanceDashboardQueriesTables

processMaintenanceDashboardQueriesTodoAggrTables

processMaintenanceTicketsProjectsTodoAggr1Tables

This means data is being processed for different modules (Tickets, Dashboards, Projects) simultaneously.


"My main responsibility is to maintain, enhance, and troubleshoot this pipeline. Specifically, I:

Develop new nodes (jobs) when business wants new aggregations or metrics.

Optimize existing Spark/SQL jobs to improve performance.

Monitor this DAG daily via the Oozie UI and fix failures (data quality, resource issues, EMR errors).

Work closely with downstream consumers like the Dashboard or Analytics teams to ensure data accuracy."


Topic	Concepts to Cover
Data Pipelines	Batch vs Streaming, ETL vs ELT, Pipeline Design Patterns
DAG Concepts	What is DAG, why acyclic?, parallelism, scheduling
Workflow Orchestration	Oozie (since you're using it), Airflow basics, dependency management, retries
Big Data Tools	Spark (RDD, DataFrame, SparkSQL, Optimization, Actions, Transformations)
Distributed Systems	Partitioning, Shuffling, Fault Tolerance, Checkpointing
AWS & EMR	How EMR works, EMR + Spark setup, EMRFS, S3 integration
SQL	Window Functions, Joins, Aggregations, Common Table Expressions (CTE)
Data Modeling	Star Schema, Snowflake Schema, Fact and Dimension tables
Performance Tuning	Spark tuning, partitioning strategy, memory optimization
Monitoring	Logs, Metrics, handling failure scenarios, EMR & Oozie Monitoring


"I currently work as a Data Engineer responsible for building and managing distributed data pipelines.
Most of my work revolves around building Spark jobs orchestrated through Oozie, running on AWS EMR clusters. 
I ensure that data is ingested, transformed, and made available to downstream systems like dashboards and analytics platforms efficiently and reliably."

Pipeline Name	Maintenance Pipeline - Snowflake Full Load
Pipeline ID	Unique ID generated for every Oozie workflow execution
Cluster	The EMR cluster where Spark & other jobs run (uswest2-emr6-analytics02-gv-prod)
Artifact	The project/deployment we use (kh-analytics-dashboards - latest)
User	The ID under which the job runs (kha22)
Start / End	Pipeline ran on 29th March 2025, took around 4 hours 51 mins
Status	Job has successfully completed (SUCCEEDED)
Actions Completed	This pipeline finished 3 actions successfully
Navigation	We use DAG, Timeline, Actions, Metadata tabs to monitor progress & logs


✨ Steps Behind The Scene (Typical Flow)
Pipeline Trigger (Oozie Workflow + Cron)

Scheduled to run daily.

Starts with a full data pull or delta extraction.

Data Ingestion (Spark + EMR)

Spark reads data from S3 / source systems.

Handles massive volume using distributed processing.

Data Transformation

Business logic applied (joins, filters, aggregations).

Data is split into multiple output tables for dashboards, reports, and monitoring.

Load into Snowflake

Final transformed data is loaded into Snowflake using Snowflake Connector or Snowflake Spark JDBC.

Dashboard Ready

Data is now available for Tableau / Reporting tools.

Stakeholders use this for daily decision-making.


"If the pipeline fails, we check Spark UI, EMR logs, Oozie logs to identify the failure point. 
We fix the issue, whether it's data corruption, resource limits, or logic errors, and then we trigger a rerun either fully or partially depending on the failure point."


✅ Simple Story You Can Use
"Recently, I optimized one of the heavy transformations in this pipeline by reducing unnecessary shuffles and repartitioning, which reduced the runtime by 40 minutes. 
This not only improved performance but also made downstream Tableau dashboards available earlier every morning."



This pipeline is part of a data refresh system for Kitty Hawk Maintenance analytics. It does two big jobs:

- Loads & processes data from Snowflake by running a series of Snowflake SQL scripts (via SqlRunner).

- Refreshes Tableau dashboards automatically after the data is ready.


Script of the pipeline 

1. Pipeline Metadata & Constants :-----

- pipelineName, pipelineDescription — Just info about what this pipeline is.

- snowflakeScriptRunnerClass — Points to the Java class that will execute Snowflake SQL scripts.

- tableauRefresh — Points to the Java class that triggers Tableau API refresh.


2. List of Tableau Dashboards

val khMaintenanceTableauDashboards = List(...)


3. 




---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


SPARK PIPELINE :-

how large companies build and manage their data infrastructure using tools that help automate, schedule, and run data workflows at scale.

An Enterprise Data Platform is a system 

- Cloud storage (S3, ADLS)

- Data warehouses (Snowflake, BigQuery, Redshift)

- Data processing engines (Spark, Flink, Hive)

- Workflow orchestration (Oozie, Airflow)


Pipeline Configuration :-

Spectrum Compliance Snowflake Pipeline

- The pipeline config (JSON or XML for Oozie) is stored in a Git repo.

- This configuration sets up how a Spark job will be submitted and executed on a Hadoop cluster with the below points

1. Resource allocation (memory, cores, instances)

2. Job behavior (timeouts, dynamic allocation)

3. Cluster scheduling (queue name, fairness)

4. Snowflake export likely happens at the end via a connector or JDBC


val sparkConfigs = Map(
    "spark.executor.cores" -> "4",
    "spark.scheduler.mode" -> "FAIR",
    "spark.executor.heartbeatInterval" -> "60s",
    "spark.app.name" -> "processcontext=ANALYTICS.kh-build-ops-analytics-prod.AGGREGATES_PROD usercontext=kha22",
    "spark.yarn.am.memory" -> "48g",
    "spark.driver.memory" -> "48g",
    "spark.driver.userClassPathFirst" -> "false",
    "spark.dynamicAllocation.maxExecutors" -> "10",
    "spark.network.timeout" -> "3600s",
    "spark.rpc.askTimeout" -> "3600s",
    "spark.rpc.message.maxSize" -> "850",
    "spark.yarn.am.waitTime" -> "3600s",
    "spark.dynamicAllocation.minExecutors" -> "1",
    "spark.executor.userClassPathFirst" -> "false",
    "spark.yarn.queue" -> "ANALYTICS.AGGREGATES_PROD.AGGREGATES_PROD",
    "spark.executor.instances" -> "5",
    "spark.storage.memoryFraction" -> "0.05",
    "spark.executor.memory" -> "16g",
    "spark.kryoserializer.buffer.max" -> "1024m",
    "spark.shuffle.service.enabled" -> "true",
    "spark.yarn.driver.memoryOverhead" -> "4096",
    "spark.yarn.am.memoryOverhead" -> "4096",
    "spark.yarn.executor.memoryOverhead" -> "1600",
    "spark.driver.extraClassPath" -> "../config/hadoop-alt:../config/hive"
  )

1. Core Resource Settings

"spark.executor.cores" -> "4"
"spark.executor.memory" -> "16g"
"spark.executor.instances" -> "5"
"spark.driver.memory" -> "48g"

Each executor gets 4 CPU cores.
More cores = more parallel tasks per executor.
Each executor gets 16 GB RAM (for processing).
5 executors will be launched.

Total Spark resources: 5 executors × 4 cores = 20 cores, and 5 × 16 GB = 80 GB of executor memory (plus overhead).

The driver (master program) and ApplicationMaster get 48 GB RAM — quite high, meaning your pipeline is doing substantial orchestration or data movement.


2. Execution Environment & Optimization

"spark.dynamicAllocation.minExecutors" -> "1"
"spark.dynamicAllocation.maxExecutors" -> "10"

Spark will scale executors between 1 and 10 based on the job load.

Works only if dynamic allocation is enabled 

"spark.shuffle.service.enabled" -> "true"

Required for dynamic allocation to work (because shuffled data may be reused between executors).

"spark.storage.memoryFraction" -> "0.05"

Only 5% of executor memory is used for caching/storage. You’re optimizing more for computation than caching.

Executor memory in Spark is divided between:
Storage memory → used for caching (e.g., .cache(), .persist() results).
Execution memory → used for computation (e.g., joins, shuffles, aggregations).

Optimization - Not caching large reused DataFrames means missed opportunity for faster pipelines.
Performance	Without caching - Spark recomputes data multiple times, increasing job duration.

Caching - It allows Spark to keep data in memory rather than recomputing it or reading it again from disk or a remote source (like Snowflake or HDFS).

When you re-use the same DataFrame/RDD multiple times, Spark will by default recompute it each time unless you tell it to cache or persist.

Persist - Storage Level	MEMORY_AND_DISK (default)	Customizable (e.g., MEMORY_ONLY, DISK_ONLY)
Caching - Usage Simplicity	Shorthand for common case	Flexible with more options


Why Spark Recomputes Without cache() ? 

- Spark uses lazy evaluation, so it doesn’t immediately execute this line.
It builds a logical execution plan (a DAG) — a graph of operations to be executed only when an action is triggered (like .count(), .collect(), .write()).

{val df = spark.read.parquet("/big/path")
val filtered = df.filter("status = 'active'").select("user_id")

val result1 = filtered.groupBy("user_id").count()
val result2 = filtered.where("user_id > 1000").count()} 

For result1, Spark builds a DAG that goes:
Read Parquet → Filter → Select → GroupBy

For result2, Spark builds another DAG:
Read Parquet → Filter → Select → Where






3. 


































